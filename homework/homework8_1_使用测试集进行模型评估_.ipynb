{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOOnXjbOESAsU2I1AqqWK9U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jiangxueqi/LLM-quickstart/blob/main/homework/homework8_1_%E4%BD%BF%E7%94%A8%E6%B5%8B%E8%AF%95%E9%9B%86%E8%BF%9B%E8%A1%8C%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1wFciAdjF6b"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r \"/content/drive/MyDrive/Colab Notebooks/AI大模型微调训练营/8_大模型高效微调工具PEFT/requirements.txt\""
      ],
      "metadata": {
        "id": "J9fFQABXjcCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1、全局参数设置"
      ],
      "metadata": {
        "id": "rykc17_kj6cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name_or_path = \"openai/whisper-large-v2\"\n",
        "model_dir = \"models/whisper-large-v2-asr-int8\"\n",
        "\n",
        "language = \"Chinese (China)\"\n",
        "language_abbr = \"zh-CN\"\n",
        "task = \"transcribe\"\n",
        "dataset_name = \"mozilla-foundation/common_voice_11_0\"\n",
        "\n",
        "batch_size=64"
      ],
      "metadata": {
        "id": "NB2UZOifj9Tj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2、数据准备"
      ],
      "metadata": {
        "id": "e1BfUz63kArt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.1、下载数据集Common Voice"
      ],
      "metadata": {
        "id": "IEaPBFjAkGM5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, DatasetDict\n",
        "\n",
        "common_voice = DatasetDict()\n",
        "\n",
        "common_voice[\"train\"] = load_dataset(dataset_name, language_abbr, split=\"train\", trust_remote_code=True)\n",
        "common_voice[\"validation\"] = load_dataset(dataset_name, language_abbr, split=\"validation\", trust_remote_code=True)\n",
        "\n",
        "common_voice[\"train\"][0]"
      ],
      "metadata": {
        "id": "Dy04wd5MkM97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.2、预处理数据集"
      ],
      "metadata": {
        "id": "O59VDwNNk4us"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.2.1、加载处理器"
      ],
      "metadata": {
        "id": "rFcOdbSgQdst"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoProcessor\n",
        "\n",
        "# 从预训练模型加载处理器，处理器通常结合了特征提取器和分词器，为特定任务提供一站式的数据预处理\n",
        "processor = AutoProcessor.from_pretrained(model_name_or_path, language=language, task=task)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, language=language, task=task)\n",
        "feature_extractor = processor.feature_extractor"
      ],
      "metadata": {
        "id": "9qgEynBUQjjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.2.2、移除数据集中不必要的字段"
      ],
      "metadata": {
        "id": "zQ8LbUFrQtos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "common_voice = common_voice.remove_columns(\n",
        "    [\"accent\", \"age\", \"client_id\", \"down_votes\", \"gender\", \"locale\", \"path\", \"segment\", \"up_votes\"]\n",
        ")"
      ],
      "metadata": {
        "id": "cFBKEd7-Q1f_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "common_voice[\"train\"][0]"
      ],
      "metadata": {
        "id": "fNrIZosyQ5mc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.2.3、重新采样，计算输入特征、标记输入标签"
      ],
      "metadata": {
        "id": "Tvnw6DVWQ95H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_dataset(batch):\n",
        "    audio = batch[\"audio\"]\n",
        "    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
        "    batch[\"labels\"] = tokenizer(batch[\"sentence\"]).input_ids\n",
        "    return batch"
      ],
      "metadata": {
        "id": "eL6wbzMxRMX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_common_voice = common_voice.map(prepare_dataset)"
      ],
      "metadata": {
        "id": "ee0ddUUTRRsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.2.4、自定义语音数据整理器"
      ],
      "metadata": {
        "id": "1FnEQikLRbPp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Any, Dict, List, Union\n",
        "\n",
        "# 定义一个针对语音到文本任务的数据整理器类\n",
        "@dataclass\n",
        "class DataCollatorSpeechSeq2SeqWithPadding:\n",
        "    processor: Any  # 处理器结合了特征提取器和分词器\n",
        "\n",
        "    # 整理器函数，将特征列表处理成一个批次\n",
        "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
        "        # 从特征列表中提取输入特征，并填充以使它们具有相同的形状\n",
        "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
        "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
        "\n",
        "        # 从特征列表中提取标签特征（文本令牌），并进行填充\n",
        "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
        "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
        "\n",
        "        # 使用-100替换标签中的填充区域，-100通常用于在损失计算中忽略填充令牌\n",
        "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
        "\n",
        "        # 如果批次中的所有序列都以句子开始令牌开头，则移除它\n",
        "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
        "            labels = labels[:, 1:]\n",
        "\n",
        "        # 将处理过的标签添加到批次中\n",
        "        batch[\"labels\"] = labels\n",
        "\n",
        "        return batch  # 返回最终的批次，准备好进行训练或评估"
      ],
      "metadata": {
        "id": "RS-vaWCuRh1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 用给定的处理器实例化数据整理器\n",
        "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)"
      ],
      "metadata": {
        "id": "ubBMnxXaRlz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3、模型准备"
      ],
      "metadata": {
        "id": "WtHczmCQRtzj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3.1、加载预训练模型（int8精度）"
      ],
      "metadata": {
        "id": "2oH1GrxjR75A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSpeechSeq2Seq\n",
        "\n",
        "model = AutoModelForSpeechSeq2Seq.from_pretrained(model_name_or_path, load_in_8bit=True, device_map=\"auto\")"
      ],
      "metadata": {
        "id": "R_WM-3f0SCd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 设置模型配置中的forced_decoder_ids属性为None\n",
        "model.config.forced_decoder_ids = None  # 这通常用于指定在解码（生成文本）过程中必须使用的特定token的ID，设置为None表示没有这样的强制要求\n",
        "\n",
        "# 设置模型配置中的suppress_tokens列表为空\n",
        "model.config.suppress_tokens = []  # 这用于指定在生成过程中应被抑制（不生成）的token的列表，设置为空列表表示没有要抑制的token"
      ],
      "metadata": {
        "id": "OpvRV0W-SID9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3.2、PEFT微调前模型处理"
      ],
      "metadata": {
        "id": "qm97P0vgSNOq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import prepare_model_for_int8_training\n",
        "\n",
        "model = prepare_model_for_int8_training(model)"
      ],
      "metadata": {
        "id": "NlCIvDJ5SWIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3.3、LoRA Adapter配置"
      ],
      "metadata": {
        "id": "9_A4ZcsDScYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig, PeftModel, LoraModel, LoraConfig, get_peft_model\n",
        "\n",
        "# 创建一个LoraConfig对象，用于设置LoRA（Low-Rank Adaptation）的配置参数\n",
        "config = LoraConfig(\n",
        "    r=8,  # LoRA的秩，影响LoRA矩阵的大小\n",
        "    lora_alpha=64,  # LoRA适应的比例因子\n",
        "    # 指定将LoRA应用到的模型模块，通常是attention和全连接层的投影。\n",
        "    target_modules=[\"q_proj\", \"v_proj\"],\n",
        "    lora_dropout=0.05,  # 在LoRA模块中使用的dropout率\n",
        "    bias=\"none\",  # 设置bias的使用方式，这里没有使用bias\n",
        ")"
      ],
      "metadata": {
        "id": "toyBD74gSlv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3.4、用LoRA配置获取一个PEFT模型"
      ],
      "metadata": {
        "id": "k4qjApyGSosk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "peft_model = get_peft_model(model, config)"
      ],
      "metadata": {
        "id": "vkwqela1SwQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 打印 LoRA 微调训练的模型参数\n",
        "peft_model.print_trainable_parameters()"
      ],
      "metadata": {
        "id": "lyBkeRn-SzSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4、模型训练参数配置"
      ],
      "metadata": {
        "id": "98NEDxkpS23Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4.1、配置超参数TrainingArguments"
      ],
      "metadata": {
        "id": "jSlbtlu0bNFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainingArguments\n",
        "\n",
        "# 设置序列到序列模型训练的参数\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=model_dir,  # 指定模型输出和保存的目录\n",
        "    per_device_train_batch_size=batch_size,  # 每个设备上的训练批量大小\n",
        "    learning_rate=1e-3,  # 学习率\n",
        "    num_train_epochs=1,  # 训练的总轮数\n",
        "    evaluation_strategy=\"epoch\",  # 设置评估策略，这里是在每个epoch结束时进行评估\n",
        "    warmup_steps=50,  # 在训练初期增加学习率的步数，有助于稳定训练\n",
        "    fp16=True,  # 启用混合精度训练，可以提高训练速度，同时减少内存使用\n",
        "    per_device_eval_batch_size=batch_size,  # 每个设备上的评估批量大小\n",
        "    generation_max_length=128,  # 生成任务的最大长度\n",
        "    logging_steps=10,  # 指定日志记录的步骤，用于跟踪训练进度\n",
        "    remove_unused_columns=False,  # 是否删除不使用的列，以减少数据处理开销\n",
        "    label_names=[\"labels\"],  # 指定标签列的名称，用于训练过程中\n",
        ")"
      ],
      "metadata": {
        "id": "rIWHG78Ja_9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4.2、配置评估指标"
      ],
      "metadata": {
        "id": "D94jzCawbYCv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "\n",
        "# 词错误率（WER）是评估ASR模型常用的指标。从 Evaluate加载 WER 指标\n",
        "metric = evaluate.load(\"wer\")"
      ],
      "metadata": {
        "id": "VarTe-NdbXb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics():\n",
        "  wer = 100 * metric.compute()\n",
        "  return wer"
      ],
      "metadata": {
        "id": "HVuXm67-kYhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5、训练过程"
      ],
      "metadata": {
        "id": "s1XZxgIEekhF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5.1、实例化Seq2SeqTrainer 训练器"
      ],
      "metadata": {
        "id": "sZ3gNw4JfBPm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainer\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    args=training_args,\n",
        "    model=peft_model,\n",
        "    train_dataset=tokenized_common_voice[\"train\"],\n",
        "    eval_dataset=tokenized_common_voice[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=processor.feature_extractor,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "peft_model.config.use_cache = False"
      ],
      "metadata": {
        "id": "iOYSxD4cfGys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5.2、训练"
      ],
      "metadata": {
        "id": "xG_4BO0VfUgi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "ai4jrFFQfW3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5.3、保存LoRA模型（Adapter）"
      ],
      "metadata": {
        "id": "u3_NJFXKfgNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model(model_dir)"
      ],
      "metadata": {
        "id": "GjzJzOt3foAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6、模型评估"
      ],
      "metadata": {
        "id": "yHXTRO30gCG8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##6.1、获取训练好的模型"
      ],
      "metadata": {
        "id": "5z0MLHjtgvkX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSpeechSeq2Seq, AutoTokenizer, AutoProcessor\n",
        "from peft import PeftConfig, PeftModel\n",
        "\n",
        "peft_config = PeftConfig.from_pretrained(model_dir)\n",
        "\n",
        "base_model = AutoModelForSpeechSeq2Seq.from_pretrained(peft_config.base_model_name_or_path, load_in_8bit=True, device_map=\"auto\")\n",
        "base_model.requires_grad_(False)"
      ],
      "metadata": {
        "id": "9DId3SjPgoWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "peft_model = PeftModel.from_pretrained(base_model, model_dir)"
      ],
      "metadata": {
        "id": "XnQ2TVBwhAxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(peft_config.base_model_name_or_path, language=language, task=task)\n",
        "processor = AutoProcessor.from_pretrained(peft_config.base_model_name_or_path, language=language, task=task)\n",
        "feature_extractor = processor.feature_extractor"
      ],
      "metadata": {
        "id": "TViAZU5OhIRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##6.2、处理评估数据集"
      ],
      "metadata": {
        "id": "GIUuqD0-hday"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, DatasetDict, Audio\n",
        "\n",
        "common_voice = DatasetDict()\n",
        "common_voice[\"test\"] = load_dataset(dataset_name, language_abbr, split=\"test\", trust_remote_code=True)\n",
        "common_voice = common_voice.remove_columns(\n",
        "    [\"accent\", \"age\", \"client_id\", \"down_votes\", \"gender\", \"locale\", \"path\", \"segment\", \"up_votes\"]\n",
        ")"
      ],
      "metadata": {
        "id": "rvrM9axuhk6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_dataset(batch):\n",
        "    audio = batch[\"audio\"]\n",
        "    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
        "    batch[\"labels\"] = tokenizer(batch[\"sentence\"]).input_ids\n",
        "    return batch"
      ],
      "metadata": {
        "id": "r1jkyn_2hvDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_tokenized_common_voice = common_voice.map(prepare_dataset)"
      ],
      "metadata": {
        "id": "M6mWJ4nlh0Mk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 用给定的处理器实例化数据整理器\n",
        "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)"
      ],
      "metadata": {
        "id": "K5ox1UtaiO6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##6.3、评估模型"
      ],
      "metadata": {
        "id": "170k15DfiVIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import gc\n",
        "\n",
        "eval_dataloader = DataLoader(test_tokenized_common_voice[\"test\"], batch_size=batch_size, collate_fn=data_collator)"
      ],
      "metadata": {
        "id": "vsfXW2FtiYiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 遍历评估数据加载器中的所有批次\n",
        "for step, batch in enumerate(tqdm(eval_dataloader)):\n",
        "    # 使用自动混合精度来加速计算，并减少显存使用\n",
        "    with torch.cuda.amp.autocast():\n",
        "        # 不计算梯度，以节省计算资源，仅用于推理和评估\n",
        "        with torch.no_grad():\n",
        "            # 生成预测的标记(tokens)，这里使用模型的generate函数进行文本生成\n",
        "            generated_tokens = (\n",
        "                peft_model.generate(\n",
        "                    input_features=batch[\"input_features\"].to(\"cuda\"),  # 将输入特征移动到GPU上\n",
        "                    decoder_input_ids=batch[\"labels\"][:, :4].to(\"cuda\"),  # 提供解码器的初始输入\n",
        "                    max_new_tokens=255,  # 设置生成的最大新标记数量\n",
        "                )\n",
        "                .cpu()  # 将生成的标记移回CPU\n",
        "                .numpy()  # 转换为NumPy数组以便进一步处理\n",
        "            )\n",
        "            # 获取批次中的标签，并将其移回CPU\n",
        "            labels = batch[\"labels\"].cpu().numpy()\n",
        "            # 将标签中的-100替换为填充标记的ID，-100通常用于忽略计算损失的标记\n",
        "            labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "            # 使用分词器解码生成的标记和标签，以获得可读的文本\n",
        "            decoded_preds = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
        "            decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "            # 将预测和参考添加到评估指标中，用于后续的性能评估\n",
        "            metric.add_batch(\n",
        "                predictions=decoded_preds,\n",
        "                references=decoded_labels,\n",
        "            )\n",
        "    # 删除不再需要的变量以释放内存\n",
        "    del generated_tokens, labels, batch\n",
        "    # 手动触发垃圾收集，进一步清理内存\n",
        "    gc.collect()"
      ],
      "metadata": {
        "id": "6mEU-R_KiqJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 计算词错误率（WER）指标，并将结果转换为百分比形式\n",
        "wer = 100 * metric.compute()\n",
        "\n",
        "# 打印词错误率，f\"{wer=}\"是一种格式化字符串的简洁写法，它会展示变量名和值\n",
        "print(f\"{wer=}%\")"
      ],
      "metadata": {
        "id": "ITsZyvppiuKF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}